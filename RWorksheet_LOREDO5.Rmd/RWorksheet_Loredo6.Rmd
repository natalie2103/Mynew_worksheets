---
title: "RWorksheet_6Loredo.Rmd"
author: "Natalie Joy Loredo BSIT 2-C"
date: "2023-12-22"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```




#1.Create a data frame for the table below. Show your solution.
```{r}
  student_score <- data.frame(
  Student = c(1:10),
  Pre_test = c(55,54,47,57,51,61,57,54,63,58),
  Post_test = c(61,60,56,63,56,63,59,56,62,61)
)
  student_score

  names(student_score) <- c("Student","Pre-test","Post-test")

```

#1.a. Compute the descriptive statistics using different packages (Hmisc and pastecs). Write the codes and its result.
```{r}
  install.packages("Hmisc")
  install.packages("pastecs")

  library(Hmisc)
  library(pastecs)

#Hmisc
  describe(student_score)


#pastecs
  stat.desc(student_score)

```


#2.The Department of Agriculture was studying the effects of several levels of a fertilizer on the growth of a plant. For some analyses, it might be useful to convert the fertilizer levels to an ordered factor.
  The data were 10,10,10, 20,20,50,10,20,10,50,20,50,20,10.
```{r}
 fertilizer_level <- c(10,10,10, 20,20,50,10,20,10,50,20,50,20,10)

  ordered_level <- ordered(fertilizer_level, levels = c(10,20,50))

  ordered_level
  
#a.Describe the result.
#The numbers in the square brackets show the information or data, and below them are the levels. The arrow indicates the sequence from 10 less than to 20, and from 20 less than to 50.

```

#3. Abdul Hassan, president of Floor Coverings Unlimited, has asked you to study the exercise levels undertaken by 10 subjects were “l”, “n”, “n”, “i”, “l” , “l”, “n”, “n”, “i”, “l” ; n=none, l=light, i=intense
#a. What is the best way to represent this in R?
```{r}
  exercise_level <- c("l", "n", "n", "i", "l", "l", "n", "n", "i", "l")


  factor_exercise <- factor(exercise_level, levels = c("n", "l", "i"))

  factor_exercise
  
```

#4. Sample of 30 tax accountants from all the states and territories of Australia and their individual state of origin is specified by a character vector of state mnemonics as:
```{r}
  State <- c("tas", "sa", "qld", "nsw", "nsw", "nt", "wa", "wa", "qld",
"vic", "nsw", "vic", "qld", "qld", "sa", "tas", "sa", "nt",
"wa", "vic", "qld", "nsw", "nsw", "wa", "sa", "act", "nsw",
"vic", "vic", "act")

  Factor_state <- factor(State, levels = c("act", "nsw", "nt", "qld", "sa", "tas", "vic", "wa"))

  Factor_state
#a.Describe the results.
#The numbers in the square brackets are the things we're looking at, and below them are the regions. These regions represent specific parts of Australia.

```

#5. From #4 - continuation:Suppose we have the incomes of the same tax accountants in another vector (in suitably large units of money)
```{r}
  incomes <- c(60, 49, 40, 61, 64, 60, 59, 54,
62, 69, 70, 42, 56, 61, 61, 61, 58, 51, 48,
65, 49, 49, 41, 48, 52, 46, 59, 46, 58, 43)

  incomes_means <- tapply(incomes, Factor_state, mean)
  incomes_means
  
#It calculates the means of every states.
  
```

#6. Calculate the standard errors of the state income means (refer again to number 3)
#a. What is the standard error? Write the codes.
```{r}
  stdError <- function(x) sqrt(var(x)/length(x))
  incomester <- tapply(incomes, Factor_state, stdError)
  incomester
  
#b.Interpret the result.
 #In number 5, we look at the averages for each state. Here, we're figuring out the standard error for each state.
  #The standard errors tell us how sure we can be about the average incomes for each state. If the standard error is low, it means our estimates are more accurate. But if it's high, there's more uncertainty and variability in our estimates.

```

#7.Use the titanic dataset.
```{r}
  install.packages("titanic")
  library(titanic)

  data("titanic_train")

  survived <- subset(titanic_train, Survived == 1)

  not_survived <- subset(titanic_train, Survived == 0)

  head(survived)
  head(not_survived)

```

#8.The data sets are about the breast cancer Wisconsin. The samples arrive periodically as Dr. Wolberg reports his clinical cases.
```{r}
  breast_cancer_data <- read.csv("breastcancer_wisconsin.csv")

  str(breast_cancer_data)
  head(breast_cancer_data)
  summary(breast_cancer_data)

#The dataset is about the data of the breast cancer.

```

#8d. Compute the descriptive statistics using different packages. Find the values of:
```{r}
  install.packages("psych")
  library(psych)

  clump_thickness <- breast_cancer_data$ClumpThickness
  marginal_adhesion <- breast_cancer_data$MarginalAdhesion
  bare_nuclei <- breast_cancer_data$BareNuclei
  bland_chromatin <- breast_cancer_data$BlandChromatin
  uniformity_cell_shape <- breast_cancer_data$UniformityCellShape

#d.1 Standard error of the mean for clump thickness.
  SE_clumpthickness <- sd(clump_thickness) / sqrt(length(clump_thickness))
  SE_clumpthickness

#d.2 Coefficient of variability for Marginal Adhesion.
  CV_marginaladhesion <- sd(marginal_adhesion) / mean(marginal_adhesion)
  CV_marginaladhesion

#d.3 Number of null values of Bare Nuclei.
  nullval_barenuclei <- sum(is.na(bare_nuclei))
  nullval_barenuclei

#d.4 Mean and standard deviation for Bland Chromatin
  mean_blandchromatin <- mean(breast_cancer_data$bland_chromatin)
  sd_blandchromatin <- sd(breast_cancer_data$bland_chromatin)
  mean_blandchromatin
  sd_blandchromatin

#d.5 Confidence interval of the mean for Uniformity of Cell Shape
  ci_uniformitycellshape <- tryCatch(
  t.test(breast_cancer_data$`uniformity_cell_shape`)$conf.int,
  error = function(e) NULL
)
  ci_uniformitycellshape
  
```
#9.Export the data abalone to the Microsoft excel file. Copy the codes.
```{r, error=TRUE}
  install.packages("AppliedPredictiveModeling")
  library(AppliedPredictiveModeling)

  data("abalone")

  install.packages("openxlsx")

  library(openxlsx)

  write.xlsx(abalone, file = "abalone.xlsx")

  View(abalone)
  head(abalone)
  summary(abalone)

```
